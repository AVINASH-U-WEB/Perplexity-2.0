ğŸ¤– AI Agent Development Platform
A sophisticated full-stack AI agent platform built with FastAPI, LangGraph, and React.
This system provides intelligent web search, content fetching, and tool utilization capabilities through a powerful AI agent architecture.

ğŸ“Œ Overview
This platform combines the power of LangGraph's agentic workflows with Groq's high-performance LLM inference to create a robust AI assistant capable of:

Web search

Content analysis

Mathematical computation

Real-time information retrieval

âœ¨ Features
ğŸ¤– AI Agent System â€“ Powered by LangGraph with ReAct reasoning

ğŸŒ Web Search Integration â€“ Multiple providers (Tavily, SerpAPI, DuckDuckGo)

ğŸ“„ Content Fetching & Summarization â€“ Intelligent page retrieval & analysis

ğŸ§® Tool Ecosystem â€“ Calculator, time retrieval, and custom tools

ğŸ’¾ Intelligent Caching â€“ Redis-backed cache for performance optimization

âš¡ High-Performance Inference â€“ Groq's ultra-fast LLM engine

ğŸ”„ Real-time Streaming â€“ SSE-based token streaming for responsive UI

ğŸ§­ State Management â€“ Conversation threading and memory persistence

ğŸ— Architecture
System Components


Frontend (React) â†’ Backend (FastAPI) â†’ LangGraph Agent â†’ Groq LLM
       â”‚              â”‚          â”‚
       â”‚              â”‚          â””â”€â”€ Tool Ecosystem
       â”‚              â”‚               â€¢ Web Search
       â”‚              â”‚               â€¢ Content Fetching
       â”‚              â”‚               â€¢ Calculator
       â”‚              â”‚               â€¢ Time Service
       â”‚              â”‚
       â”‚              â””â”€â”€ Cache Layer (Redis)
       â”‚
       â””â”€â”€ Real-time Updates (SSE)



Workflow
<img width="5190" height="2619" alt="deepseek_mermaid_20250820_5f176e" src="https://github.com/user-attachments/assets/1130f99d-fa55-4e8c-b859-6b991eb1809d" />


ğŸ›  Technology Stack
Backend

FastAPI â€“ High-performance API framework

LangGraph â€“ Agent orchestration & state management

Groq â€“ Ultra-fast LLM inference engine

Redis â€“ Distributed caching & session storage

BeautifulSoup4 â€“ HTML parsing & content extraction

Frontend

React â€“ Modern UI framework with hooks

Chakra UI â€“ Accessible component library

Axios â€“ HTTP client for API calls

SSE Client â€“ Real-time updates (Server-Sent Events)

Tools & Services

Tavily â€“ AI-optimized web search

SerpAPI â€“ Google search results API

DuckDuckGo â€“ Privacy-focused search engine

âš™ï¸ Installation
Prerequisites
Python 3.9+

Node.js 16+

Redis server

Groq API account

Backend Setup
bash
# Clone repository
git clone <repo-url>
cd ai-agent-platform

# Setup Python environment
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Setup environment variables
cp .env.example .env
# Edit .env with your API keys and settings

# Start backend server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
Frontend Setup
bash
cd frontend

# Install dependencies
npm install

# Start development server
npm start
ğŸ”‘ Configuration
Create a .env file with:

env
# Groq Configuration
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.1-70b-versatile

# Search API Keys
TAVILY_API_KEY=your_tavily_api_key
SERPAPI_API_KEY=your_serpapi_api_key

# Redis
REDIS_URL=redis://localhost:6379/0

# CORS
CORS_ORIGINS=http://localhost:3000

# Debug
DEBUG=True
ğŸ“– API Documentation
Once running:

Swagger UI â†’ http://localhost:8000/docs

ReDoc â†’ http://localhost:8000/redoc

ğŸ”Œ Key Endpoints
POST /api/chat â€“ Send messages to the AI agent

GET /api/chat/stream â€“ Stream responses in real-time

GET /health â€“ Health check

GET /providers â€“ List available AI providers

ğŸš€ Usage Examples
Basic Chat
javascript
const response = await fetch('/api/chat', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    messages: [{ role: 'user', content: 'What is the capital of France?' }]
  })
});
Tool Utilization
"Calculate 45 * 87" â†’ Calculator tool

"What's the current time in IST?" â†’ Time tool

"Search for latest AI news" â†’ Web search tool

"Summarize this article: https://example.com" â†’ Content fetching tool

ğŸ“‚ Project Structure
text
ai-agent-platform/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py          # FastAPI application
â”‚   â”œâ”€â”€ graph.py         # LangGraph agent definition
â”‚   â”œâ”€â”€ providers.py     # LLM provider configuration
â”‚   â”œâ”€â”€ cache.py         # Redis caching system
â”‚   â”œâ”€â”€ state.py         # Agent state management
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ tools_core.py   # Basic tools (calculator, time)
â”‚       â”œâ”€â”€ search_tools.py # Web search tools
â”‚       â””â”€â”€ fetch_tools.py  # Content fetching tools
â”œâ”€â”€ frontend/             # React application
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
ğŸ›  Adding New Tools
Create a new tool

python
@tool
def my_new_tool(parameter: str) -> str:
    """Description of what the tool does."""
    # Implementation
    return result
Register it in app/graph.py

python
from app.tools.my_tools import my_new_tool

TOOLS = [calculator, now_ist, web_search, web_get, my_new_tool]
âš¡ Performance Considerations
Results cached in Redis to reduce LLM calls

Web search results reranked with TF-IDF cosine similarity

Content extraction limited to 4000 chars for context window

Configurable TTL in Redis prevents redundant operations

ğŸ¤ Contributing
Fork the repo

Create a feature branch (git checkout -b feature/amazing-feature)

Commit changes (git commit -m 'Add amazing feature')

Push to branch (git push origin feature/amazing-feature)

Open a Pull Request

ğŸ“œ License
This project is licensed under the MIT License â€“ see the LICENSE file.

ğŸ™ Acknowledgments
LangChain team for LangGraph

Groq for high-performance LLM inference

FastAPI for the excellent framework

All contributors and users of this platform ğŸ‰

ğŸ› Troubleshooting
If you encounter issues:

Check that all environment variables are set correctly

Ensure Redis server is running

Verify API keys have proper permissions

Check the logs for detailed error messages
